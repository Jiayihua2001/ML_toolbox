{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dell/anaconda3/envs/pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from  tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'test', 'lr': 0.1, 'batch_size': 3, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open(\"config.yaml\",\"r\")as f:\n",
    "    config = yaml.safe_load(f)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD your data /data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset preparation\n",
    "import pandas as pd\n",
    "class DataLoader_train(torch.utils.data.Dataset):\n",
    "    def __init__(self,path_to_train):\n",
    "        all_data = pd.read_csv(path_to_train)\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df.head()\n",
    "        self.target = df[\"target\"]\n",
    "        self.df_features = df.drop(\"target\",axis=1)\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    def __getitem__(self,ind):\n",
    "        feature = torch.FloatTensor(self.df_features.iloc[ind]) # Convert to tensors\n",
    "        target  = torch.tensor(self.target.iloc[ind])\n",
    "        return feature,target\n",
    "\n",
    "\n",
    "class DataLoader_test(torch.utils.data.Dataset):\n",
    "    def __init__(self,path_to_test):\n",
    "        test_data = pd.read_csv(path_to_test)\n",
    "        df = pd.DataFrame(test_data)\n",
    "        df.head()\n",
    "        self.target = df[\"target\"]\n",
    "        self.df_features = df.drop(\"target\",axis=1)\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    def __getitem__(self,ind):\n",
    "        feature = torch.FloatTensor(self.df_features.iloc[ind]) # Convert to tensors\n",
    "        target  = torch.tensor(self.target.iloc[ind])\n",
    "        return feature,target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_val_dataset = DataLoader_train(\"all_data.csv\")\n",
    "train_dataset ,val_dataset = torch.utils.data.random_split(train_val_dataset, [0.8,0.2])\n",
    "test_dataset = DataLoader_test(\"all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=config[\"batch_size\"],shuffle= True)\n",
    "vac_loader = torch.utils.data.DataLoader(val_dataset,batch_size=config[\"batch_size\"],shuffle= False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=config[\"batch_size\"],shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4]) torch.Size([15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xv/tp46wlm94zz0n3x9szns5pjr0000gn/T/ipykernel_27376/746312654.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  feature = torch.FloatTensor(self.df_features.iloc[ind]) # Convert to tensors\n"
     ]
    }
   ],
   "source": [
    "# Get first training sample & label pair\n",
    "for i,data in enumerate(train_loader):\n",
    "    feature,target = data\n",
    "    print(feature.shape,target.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define your nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(Network,self).__init__()\n",
    "        self.size = 1024\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size,input_size*2),\n",
    "            torch.nn.BatchNorm1d(input_size*2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(input_size*2,input_size),\n",
    "            torch.nn.BatchNorm1d(input_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.Linear(input_size,output_size)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        result = self.model(x)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 8]              40\n",
      "       BatchNorm1d-2                    [-1, 8]              16\n",
      "              ReLU-3                    [-1, 8]               0\n",
      "           Dropout-4                    [-1, 8]               0\n",
      "            Linear-5                    [-1, 4]              36\n",
      "       BatchNorm1d-6                    [-1, 4]               8\n",
      "              ReLU-7                    [-1, 4]               0\n",
      "           Dropout-8                    [-1, 4]               0\n",
      "            Linear-9                    [-1, 1]               5\n",
      "================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_size = feature.shape[1]\n",
    "print(input_size)\n",
    "output_size = 1\n",
    "model = Network(input_size, output_size).to(device)\n",
    "summary(model, (input_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us define the optimizer and loss\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = config[\"lr\"])\n",
    "scheduler =  torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max= config[\"epochs\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# well settled! next is to define train,eval process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2230"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
