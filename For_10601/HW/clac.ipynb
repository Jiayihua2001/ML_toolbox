{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[381 491 274 491 502]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x=np.array([[1,2,1,5],[1,5,3,3],[1,1,6,2],[1,7,2,1],[1,3,2,6]]).T\n",
    "y=np.expand_dims([16,56,18,47],axis=0)\n",
    "w=np.dot(y,x)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0242950394631678\n",
      "1.1523319193960637\n",
      "1.5364425591947517\n",
      "1.2803687993289599\n",
      "1.0242950394631678\n"
     ]
    }
   ],
   "source": [
    "A,B,C=6,3,4\n",
    "fe=np.array([[1,-2,2],[1,-1,-3],[1,-2,-3],[1,0,1],[1,2,-1]])\n",
    "for i in range(5):\n",
    "    X=fe[i,:]\n",
    "    d=np.abs(A*X[0]+B*X[1]+C*X[2])/np.sqrt(A**2+B**2+C**2)\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.390839875035466\n"
     ]
    }
   ],
   "source": [
    "print((3.6056/1.0243)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.200000000000003\n"
     ]
    }
   ],
   "source": [
    "x=[9,2,6,1,8]\n",
    "y=[1,0,3,0,1]\n",
    "sum=0\n",
    "for i in range(5):\n",
    "    sum+=3*x[i]-y[i]\n",
    "result =2/5 *sum\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =0.1\n",
    "theta =np.zeros(k+1)\n",
    "e= 0.0001 # a small threshod to stop optimization\n",
    "while delta_theta > e:\n",
    "    theta_update  = theta - a*Gradient\n",
    "    Gradient = sum([gradient[i] for i in range(N)])/N\n",
    "    delta_theta = theta_update - theta\n",
    "    theta = theta_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "[[0.33333333]\n",
      " [0.33333333]\n",
      " [0.66666667]\n",
      " [0.33333333]]\n",
      "0.7975475820294224\n",
      "[ 0.20439362 -0.0416572   0.17090818]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(theta,X):\n",
    "    theta_T=np.transpose(theta)\n",
    "    N,M=np.shape(X)\n",
    "    fi_l=[1/(1+np.exp(-theta_T@X[i,:])) for i in range(N)]\n",
    "    fi=np.array(fi_l)\n",
    "    return fi\n",
    "\n",
    "\n",
    "def J(theta,X,Y):\n",
    "    \"\"\"\n",
    "    negative likelihood \n",
    "    \"\"\"\n",
    "    N,M=np.shape(X)\n",
    "    fi=sigmoid(theta,X)\n",
    "    J = sum([-Y[i]*np.log(fi[i])-(1-Y[i])*np.log(1-fi[i]) for i in range(N)])/N\n",
    "    return J\n",
    "\n",
    "    \n",
    "def G_J(theta,X,Y):\n",
    "    \"\"\"\n",
    "    gradient of negative likelihood \n",
    "    \"\"\"\n",
    "    N,M=np.shape(X)\n",
    "    fi=sigmoid(theta,X)\n",
    "    G_l=[]\n",
    "    for j in range(M):\n",
    "        G_J_j= sum([(fi[i]-Y[i])*X[i,j] for i in range(N)])/N\n",
    "        G_l.append(G_J_j)\n",
    "    G_J=np.array(G_l)\n",
    "    return G_J\n",
    "\n",
    "theta=np.array([1.5,2,1])\n",
    "Y=np.array([0,1,1,0])\n",
    "X=np.array([[0,0,1],[0,1,0],[0,1,1],[1,0,0]])\n",
    "print(np.shape(X[1,:]))\n",
    "mean=np.mean(X,axis=1,keepdims=True)\n",
    "print(mean)\n",
    "J=J(theta,X,Y)\n",
    "G_J = G_J(theta,X,Y)\n",
    "print(J)\n",
    "print(G_J)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(output_path,data):\n",
    "    with open(output_path,'w') as wf:\n",
    "        wf.write(data) \n",
    "\n",
    "data=np.array([[0,0,1],[0,1,0],[0,1,1],[1,0,0]])\n",
    "write_output('write',str(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "l=[1,1,1,2]\n",
    "l.append(1)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(theta, X):\n",
    "    # Ensure theta is a column vector\n",
    "    z = np.dot(X, theta)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def G_J(theta, X, Y):\n",
    "    \"\"\"\n",
    "    Vectorized gradient of negative log-likelihood.\n",
    "    \"\"\"\n",
    "    N, M = X.shape\n",
    "    fi = sigmoid(theta, X)\n",
    "    gradient = np.dot(X.T, (fi - Y)) / N\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def predict(theta, X):\n",
    "    \"\"\"\n",
    "    Vectorized prediction function.\n",
    "    \"\"\"\n",
    "    # Compute probabilities using the sigmoid function\n",
    "    probabilities = sigmoid(theta, X)\n",
    "    # Convert probabilities to 0 or 1 based on a 0.5 threshold\n",
    "    return (probabilities >= 0.5).astype(np.int64)\n",
    "\n",
    "\n",
    "def train(theta, X, Y, num_epoch, learning_rate):\n",
    "    \"\"\"\n",
    "    theta : np.ndarray, shape (D,) where D is feature dimension\n",
    "    X : np.ndarray, shape (N, D) where N is number of examples\n",
    "    Y : np.ndarray, shape (N,)\n",
    "    num_epoch : int, \n",
    "    learning_rate : float\n",
    "    \"\"\"\n",
    "    for _ in range(num_epoch):\n",
    "        gradient = G_J(theta, X, Y)\n",
    "        theta -= learning_rate * gradient\n",
    "    return theta\n",
    "\n",
    "# Example of initialization and training\n",
    "D = X.shape[1]  # Number of features\n",
    "theta = np.zeros(D)  # Initialize theta\n",
    "theta = train(theta, X, Y, num_epoch=100, learning_rate=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "l=[1,1,1,1,1]\n",
    "a=np.array(l).astype(np.int64)\n",
    "np.savetxt('try',a,fmt='%d')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1000.  2000.  3000.  4000.  5000.  6000.  7000.  8000.  9000. 10000.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.linspace(1000,10000,10)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
